{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ano/datalytics/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# plotting library\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "plotly.tools.set_credentials_file(username='shresthamanjil21', api_key='LhGoc8Zt7yNBNWCNOZtc')\n",
    "plotly.tools.set_config_file(world_readable=True, sharing='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training and testing files\n",
    "train_datas = pd.read_csv('train.tsv', sep='\\t')\n",
    "test_datas = pd.read_csv('test.tsv', sep='\\t')\n",
    "\n",
    "# separate training message and labels\n",
    "X = train_datas['Phrase']\n",
    "y = train_datas['Sentiment']\n",
    "\n",
    "# remove numbers from data\n",
    "def replace_numbers(val):\n",
    "    return re.sub(\"[^a-zA-Z]\", \" \", val)\n",
    "\n",
    "X = X.apply(replace_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and testing data in 75-25 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train(classifier, X_train, X_test, y_train, y_test):         \n",
    "    classifier.fit(X_train, y_train)    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy nb: 0.6009227220299884\n"
     ]
    }
   ],
   "source": [
    "# pipeline for vectorizing data and naive bayes classifier\n",
    "trial1 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=stopwords.words('english') + list(string.punctuation))),\n",
    "    ('classifier', MultinomialNB(alpha=0.05))\n",
    "])\n",
    "\n",
    "clf = train(trial1, X_train, X_test, y_train, y_test)\n",
    "\n",
    "nb_score = clf.score(X_test, y_test)     # accuracy score for naive bayes \n",
    "print (\"Accuracy nb: %s\" % nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy lg: 0.42902678159937935\n"
     ]
    }
   ],
   "source": [
    "# pipeline for vectorizing data and linear regression\n",
    "trial2 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=stopwords.words('english') + list(string.punctuation))),\n",
    "    ('classifier', LinearRegression())\n",
    "])\n",
    "\n",
    "lg_clf = train(trial2, X_train, X_test, y_train, y_test)\n",
    "\n",
    "lg_score = lg_clf.score(X_test, y_test)      # accuracy score for linear regression\n",
    "print (\"Accuracy lg: %s\" % lg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting top20 most and least popular words with frequencies from tfidf vectorized dictionary\n",
    "feature_vect = clf.named_steps['vectorizer'].vocabulary_\n",
    "\n",
    "sorted_feature_vect_highest = sorted(feature_vect.items(), key=lambda t: t[1], reverse=True)[:20]\n",
    "sorted_feature_vect_words_highest = [items[0] for items in sorted_feature_vect_highest]\n",
    "sorted_feature_vect_frequencies_highest = [items[1] for items in sorted_feature_vect_highest]\n",
    "\n",
    "sorted_feature_vect_lowest = sorted(feature_vect.items(), key=lambda t: t[1], reverse=True)[-20:]\n",
    "sorted_feature_vect_words_lowest = [items[0] for items in sorted_feature_vect_lowest]\n",
    "sorted_feature_vect_frequencies_lowest = [items[1] for items in sorted_feature_vect_lowest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ano/datalytics/lib/python3.6/site-packages/plotly/graph_objs/_deprecations.py:318: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Font is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.layout.Font\n",
      "  - plotly.graph_objs.layout.hoverlabel.Font\n",
      "  - etc.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~shresthamanjil21/10.embed\" height=\"600px\" width=\"1300px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the frequent words in bar diagram\n",
    "fig1 = go.Bar(x=sorted_feature_vect_words_highest, y = sorted_feature_vect_frequencies_highest)\n",
    "fig2 = go.Bar(x = sorted_feature_vect_words_lowest, y = sorted_feature_vect_frequencies_lowest)\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=2, subplot_titles=('Highest frequencies', 'Lowest frequencies'))\n",
    "\n",
    "fig.append_trace(fig1, 1, 1)\n",
    "fig.append_trace(fig2, 1, 2)\n",
    "\n",
    "fig['layout'].update(height=600, width=1300, title='Highest & Lowest frequencies word!')\n",
    "\n",
    "py.iplot(fig, filename='highest-lowest-frequency-word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the testing data on the above naive bayes model\n",
    "preds = clf.predict(test_datas.Phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting counts of all classified data\n",
    "neg_pred = np.count_nonzero(preds == 0)\n",
    "somewhat_pos_pred = np.count_nonzero(preds == 1)\n",
    "neut_pred = np.count_nonzero(preds == 2)\n",
    "somewhat_neg_pred = np.count_nonzero(preds == 3)\n",
    "pos_pred = np.count_nonzero(preds == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for pie chart\n",
    "labels = ['Positive', 'Negative', 'Somewhat Positive', 'Somewhat NEgative', 'Neutral']\n",
    "values = [pos_pred, neg_pred, somewhat_pos_pred, somewhat_neg_pred, neut_pred]\n",
    "colors = ['#FEBFB3', '#E1396C', '#96D38C', '#67c29d', '#f6f3h1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~shresthamanjil21/0 or inside your plot.ly account where it is named 'styled_pie_chart'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~shresthamanjil21/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot classification amount in pie chart\n",
    "trace = go.Pie(\n",
    "            labels=labels, values=values,\n",
    "            hoverinfo='label+percent', textinfo='value', \n",
    "            textfont=dict(size=20),\n",
    "            marker=dict(colors=colors, \n",
    "            line=dict(color='#000000', width=2))\n",
    "        )\n",
    "py.iplot([trace], filename='styled_pie_chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~shresthamanjil21/12.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the comparison of naive bayes and linear regression accuracy scores\n",
    "labels = ['Naive Bayes', 'Linear Regression']\n",
    "values = [nb_score, lg_score]\n",
    "colors = ['#FEBFB3', '#E1396C']\n",
    "\n",
    "trace = go.Pie(\n",
    "            labels=labels, values=values,\n",
    "            hoverinfo='label+percent', textinfo='value', \n",
    "            textfont=dict(size=20),\n",
    "            marker=dict(colors=colors, \n",
    "            line=dict(color='#000000', width=2))\n",
    "        )\n",
    "py.iplot([trace], filename='algorithm comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
